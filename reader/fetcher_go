package reader

import (
	"bufio"
	"fmt"
	log "github.com/sirupsen/logrus"
	"glusterfs-benchmark/conf"
	"glusterfs-benchmark/metric"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

const (
	defaultFilecount = 8192
)

type Meta struct {
	Index        uint64
	Length       uint64
	Count        uint64
	MilliSeconds uint64
}
type Fetcher struct {
	root      string
	name      string
	index     uint64
	count     uint64
	length    uint64
	writer    *bufio.Writer
	metrics   []*metric.Metric
	indexFile *os.File
	done      chan struct{}
	stop      chan struct{}
	in        chan []*Meta
	out       chan *Meta
	wg        *sync.WaitGroup
	flag      bool
	reader    Reader
	suffix  string
}

func NewFetcher(cf *conf.Conf, root string) (*Fetcher, error) {
	if cf == nil {
		return nil, fmt.Errorf("conf is nil")
	}
	filecount := uint64(cf.Count)
	if filecount < defaultFilecount {
		filecount = defaultFilecount
	}
	fetcher := &Fetcher{
		root:    root,
		name:    cf.Name,
		index:   0,
		in:      make(chan []*Meta),
		out:     make(chan *Meta),
		count:   filecount,
		stop:    make(chan struct{}),
		done:    make(chan struct{}),
		metrics: make([]*metric.Metric, 0),
		wg:      &sync.WaitGroup{},
		flag:    cf.OutputFlag,
		suffix:cf.Suffix,
	}
	fetcher.reader = NewFuseReader(cf.BufferSize)
	if cf.ApiEnable {
		fetcher.reader = nil
		/*NewApiReader(cf.Address, cf.Volume, cf.Port)
		if err != nil {
			fmt.Println(err)
			return nil, err
		}

		*/
	}
	return fetcher, nil
}
func (fetcher *Fetcher) initIndexFile() error {
	if fetcher.writer != nil && fetcher.indexFile != nil {
		fetcher.writer.Flush()
		fetcher.indexFile.Close()
		atomic.AddUint64(&fetcher.index, 1)

	}
	indexFileName := fmt.Sprintf("%s.%d", fetcher.name, fetcher.index)
	indexFile, err := os.OpenFile(indexFileName, os.O_APPEND|os.O_CREATE|os.O_RDWR, 0775)
	if err != nil {
		fmt.Println(err)
		return err
	}
	fetcher.indexFile = indexFile
	fetcher.writer = bufio.NewWriter(fetcher.indexFile)
	fmt.Printf("create file %s success", indexFileName)
	return nil
}
func (fetcher *Fetcher) appendMeta(metas []*Meta, count, length *uint64) {
	meta := &Meta{
		Index:  fetcher.index,
		Count:  *count,
		Length: *length,
	}
	metas = append(metas, meta)
	fmt.Printf("finish append index to  %s.%d,count:%d", fetcher.name, fetcher.index, *count)
	atomic.SwapUint64(count, 0)
	atomic.SwapUint64(length, 0)
}
func (fetcher *Fetcher)flush(path string,count *uint64) error {
	defer fetcher.writer.Flush()
	if _, err := fetcher.writer.WriteString(fmt.Sprintf("%s\n", path)); err != nil {
		return err
	}
	defer fetcher.writer.Flush()
	atomic.AddUint64(count, 1)
	return nil
}
func (fetcher *Fetcher) fetchIndex() error {
	defer fetcher.wg.Done()
	var count uint64
	var length uint64
	defer fetcher.indexFile.Close()
	err := fetcher.initIndexFile()
	if err != nil {
		return err
	}
	defer fmt.Println("...exit fetch index service", fetcher.root)
	fmt.Println("start fetch index from ", fetcher.root)
	metas := make([]*Meta, 0)
	err = filepath.Walk(fetcher.root,
		func(path string, f os.FileInfo, err error) error {
			if f == nil {
				return err
			}
			if f.IsDir() {
				return nil
			}
			if len(fetcher.suffix)>0 && !strings.HasSuffix(path,fetcher.suffix) {
				return nil
			}

			atomic.AddUint64(&length, uint64(f.Size()))
			if count >= fetcher.count {
				meta := &Meta{
					Index:  fetcher.index,
					Count:  count,
					Length: length,
				}
				metas = append(metas, meta)
				fmt.Printf("finish append index to  %s.%d,count:%d", fetcher.name, fetcher.index, count)
				atomic.SwapUint64(&count, 0)
				atomic.SwapUint64(&length, 0)
				if err = fetcher.initIndexFile(); err != nil {
					fmt.Println(err)
					return err
				}
			}
			fetcher.flush(path,&count)
			return nil
		})
	if err != nil {
		return err
	}
	if count < fetcher.count {
		meta := &Meta{
			Index:  fetcher.index,
			Count:  count,
			Length: length,
		}
		metas = append(metas, meta)
	}
	fetcher.in <- metas
	fmt.Printf("finish append index to  %s.%d,count:%d", fetcher.name, fetcher.index, count)
	return nil

}
func (fetcher *Fetcher) fetchIndexMeta() {
	defer fetcher.wg.Done()
Loop:
	for {
		select {
		case meta := <-fetcher.out:
			metric := metric.NewMetric(fmt.Sprintf("%s.%d", fetcher.name, meta.Index))
			metric.Compute(meta.Count, meta.Length, meta.MilliSeconds)
			indexFile := fmt.Sprintf("%s.%d", fetcher.name, meta.Index)
			fetcher.metrics = append(fetcher.metrics, metric)
			fmt.Printf("#### %s  contains %d files,files length %vmb,seconds %v", indexFile, meta.Count, float64(meta.Length)/1024/1024, float64(meta.MilliSeconds)/1000)
			break
		case <-fetcher.stop:
			fmt.Println("....exit fetch index meta service")
			break Loop
		}
	}
}
func (fetcher *Fetcher) Run() {
	fetcher.wg.Add(3)
	go fetcher.fetchIndex()
	go fetcher.fetchIndexMeta()
	go fetcher.startBackGroundJobs()
}
func (fetcher *Fetcher) Stop() {
	fetcher.stop <- struct{}{}
	fetcher.done <- struct{}{}
	defer close(fetcher.in)
	defer close(fetcher.out)
	defer close(fetcher.done)
	defer close(fetcher.stop)
	defer fetcher.wg.Wait()
}
func (fetcher *Fetcher) PrintMetric() {
	if fetcher.metrics != nil && len(fetcher.metrics) > 0 {
		sort.Slice(fetcher.metrics, func(i, j int) bool {
			return fetcher.metrics[i].Milliseconds < fetcher.metrics[j].Milliseconds
		})
		fmt.Println("################Summary Info######################")
		for _, m := range fetcher.metrics {
			m.Print()
		}
	}
}
func (fetcher *Fetcher) handleIndexFile(meta *Meta /*,wg *sync.WaitGroup */) error {
	indexFilePath := fmt.Sprintf("%s.%d", fetcher.name, meta.Index)
	fmt.Printf("....start  goroutine to  %s....", indexFilePath)
	defer fmt.Printf("....exit  goroutine to %s....", indexFilePath)
	indexFile, err := os.OpenFile(indexFilePath, os.O_RDONLY, 775)
	if err != nil {
		fmt.Println(err)
		return err
	}
	defer indexFile.Close()
	scanner := bufio.NewScanner(indexFile)
	start := time.Now()
	for scanner.Scan() {
		filePath := scanner.Text()
		if err = fetcher.reader.Read(filePath, fetcher.flag, nil); err != nil {
			atomic.SwapUint64(&meta.Count, meta.Count-1)
			continue
		}
	}
	meta.MilliSeconds = uint64(time.Since(start).Milliseconds())
	fetcher.out <- meta
	return nil
}
func (fetcher *Fetcher) startBackGroundJobs() error {
	defer fetcher.wg.Done()
Loop:
	for {
		select {
		case metas, ok := <-fetcher.in:
			if !ok {
				break Loop
			}
			for i := 0; i < len(metas); i++ {
				fmt.Printf("::%s.%d contains files :%d ", fetcher.name, metas[i].Index, metas[i].Count)
				go fetcher.handleIndexFile(metas[i])
			}
			break
		case <-fetcher.done:
			fmt.Println("....exit all jobs")
			break Loop
		}
	}
	return nil
}
